{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Jk0x62jYHQZBdRvcNCBmYKP83Isd6LEV","timestamp":1726713873582},{"file_id":"1aNPuqV1pr9lZ1jKo-LV823YOJ4UkFcl6","timestamp":1726646054033}],"collapsed_sections":["NyvxHviMpShq"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"kGlmyFQMaR-U"},"source":["# Lista de Exercício 3\n","### Introdução à Visão Computacional (SEL0339/SEL5886)\n","\n","**Instruções:**\n","\n"," 1. Esta lista consiste em 4 exercícios.\n"," 1. Deve-se colocar comentários nos códigos desenvolvidos.\n"," 1. As perguntas devem ser respondidas também como comentários no arquivo.\n"," 1. Colocar seu nome e número USP abaixo.\n"," 1. Quaisquer problemas na execução das listas, entrar em contato com os monitores.\n"," 1. Depois de terminado os exercícios, deve ser gerado um arquivo **extensão .ipynb** para ser enviado ao professor pelo E-DISCIPLINAS da disciplina até a data máxima de entrega.\n"," 1. Caso não seja enviado, o aluno ficará sem nota.\n","\n","\n","---\n","\n","\n","\n"," <table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/LAVI-USP/SEL0339-SEL5886_2024/blob/main/praticas/Lista_de_Exercicio_3.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Executar no Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/LAVI-USP/SEL0339-SEL5886_2024/blob/main/praticas/Lista_de_Exercicio_3.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />Ver codigo fonte no GitHub</a>\n","  </td>\n","</table>\n"]},{"cell_type":"markdown","metadata":{"id":"L3qYz1dB-tlT"},"source":["`Nome: `\n","\n","`Número USP: `\n"]},{"cell_type":"markdown","metadata":{"id":"b9uBe7nevota"},"source":["### Introdução:\n","\n","\n","Vamos importar as bibliotecas que iremos utilizar:"]},{"cell_type":"code","metadata":{"id":"xnKV2As4aCX1"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2 as cv\n","\n","from skimage.transform import hough_circle, hough_circle_peaks"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NyvxHviMpShq"},"source":["#### **Atenção**: os códigos abaixo são para fazer o download das imagens (EXECUTE-OS). Os mesmos não fazem parte dessa prática."]},{"cell_type":"code","metadata":{"id":"Amk5CM273Afp"},"source":["import urllib.request\n","\n","\n","try:\n","  urllib.request.urlretrieve(\"https://github.com/LAVI-USP/SEL0339-SEL5886_2024/raw/main/imagens/pratica_03/wirebond_mask.tif\", \"wirebond_mask.tif\")\n","except:\n","  print(\"[ERRO] Não foi possível fazer o download das imagens dessa prática. Entre em contato com o monitor\")\n","\n","try:\n","  urllib.request.urlretrieve(\"https://github.com/LAVI-USP/SEL0339-SEL5886_2024/raw/main/imagens/pratica_03/house.tif\", \"house.tif\")\n","except:\n","  print(\"[ERRO] Não foi possível fazer o download das imagens dessa prática. Entre em contato com o monitor\")\n","\n","try:\n","  urllib.request.urlretrieve(\"https://github.com/LAVI-USP/SEL0339-SEL5886_2024/raw/main/imagens/pratica_03/abobora.tif\", \"abobora.tif\")\n","except:\n","  print(\"[ERRO] Não foi possível fazer o download das imagens dessa prática. Entre em contato com o monitor\")\n","\n","try:\n","  urllib.request.urlretrieve(\"https://github.com/LAVI-USP/SEL0339-SEL5886_2024/raw/main/imagens/pratica_03/sudoku.tif\", \"sudoku.tif\")\n","except:\n","  print(\"[ERRO] Não foi possível fazer o download das imagens dessa prática. Entre em contato com o monitor\")\n","\n","\n","try:\n","  urllib.request.urlretrieve(\"https://github.com/LAVI-USP/SEL0339-SEL5886_2024/raw/main/imagens/pratica_03/cores.jpeg\", \"cores.jpeg\")\n","except:\n","  print(\"[ERRO] Não foi possível fazer o download das imagens dessa prática. Entre em contato com o monitor\")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IHz3lrkyumoo"},"source":["## 1) Detector de bordas\n","\n","#### 1.1) Prewitt e Sobel (Nota 1.5/10)\n","\n","1. Aplicar os detectores de bordas **verticais e horizontais** de Prewitt na imagem ```wirebond_mask.tif```. Mostre a imagens original e as resultantes em um subplot.\n","\n","2. Aplicar os detectores de bordas **verticais e horizontais** de Sobel na imagem ```wirebond_mask.tif```. Mostre a imagens original e as resultantes em um subplot.\n","\n","2. Comente os resultados encontrados.\n","\n","**Dicas:**\n","\n","* Nós criamos uma lista contendo os *kernels* de cada método. Note que vários *kernels* foram fornecidos abaixo. Alguns serão utilizados no próximo exercício também.\n","* Você pode criar um laço de repetição para pegar cada kernel da lista. Segue abaixo um exemplo de um `for loop` em uma lista.\n","\n","``` python\n","kernel_lista = [kernel1,kernel2,kernel3]\n","for kernel in kernel_lista:\n","  print(kernel)\n","\n","```"]},{"cell_type":"code","metadata":{"id":"Y8WjFiu1b4_h"},"source":["# Prewitt\n","p1 = np.array(((-1,-1,-1),\n","               ( 0, 0, 0),\n","               ( 1, 1, 1)))\n","\n","p2 = np.array(((-1, 0, 1),\n","               (-1, 0, 1),\n","               (-1, 0, 1)))\n","\n","# Lista com todos os kernels (Prewitt)\n","prewitt = [p1,p2]\n","\n","# Sobel\n","s1 = np.array(((-1,-2,-1),\n","               ( 0, 0, 0),\n","               ( 1, 2, 1)))\n","\n","s2 = np.array(((-1, 0, 1),\n","               (-2, 0, 2),\n","               (-1, 0, 1)))\n","\n","s3 = np.array(((-2,-1, 0),\n","               (-1, 0, 1),\n","               ( 0, 1, 2)))\n","\n","s4 = np.array((( 0, 1, 2),\n","               (-1, 0, 1),\n","               (-2,-1, 0)))\n","\n","s5 = np.array((( 2, 1, 0),\n","               ( 1, 0,-1),\n","               ( 0,-1,-2)))\n","\n","s6 = np.array((( 0,-1,-2),\n","               ( 1, 0,-1),\n","               ( 2, 1, 0)))\n","\n","# Lista com todos os kernels (Sobel)\n","sobel = [s1,s2,s3,s4,s5,s6]\n","\n","# Laplaciano\n","laplaciano = np.array(((-1,-1,-1),\n","                       (-1, 8,-1),\n","                       (-1,-1,-1)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## -- Seu código termina AQUI -- ##\n","\n","## -- Seu código termina AQUI -- ##"],"metadata":{"id":"BqIIUjRUr3tJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1.2) Sobel e Laplaciano (Nota 1.5/10)\n","\n","1. Leia a imagem ```house.tif```. Mostre a imagem na tela.\n","2. Aplique todos os detectores de bordas de Sobel na imagem lida no item 1. Mostre as imagens resultantes em um subplot.\n","2. Para cada *kernel*, aplique um *threshold* no resultado do filtro a fim de tentar manter somente as bordas que aquele filtro foi desenvolvido para detectar (nas dicas deixamos um valor sugerido). Mostre as imagens resultantes em um subplot.\n","3. Some o resultado obtido por cada *kernel* (após a aplicação do *threshold* ) em uma variável chamada  ```sobel_sum ```.\n","3. Aplique o detector de bordas Laplaciano na imagem ```house.tif```. Mostre em um subplot a imagem original, a soma de todos os resultados de Sobel (```sobel_sum```) e o resultado do Laplaciano (lembre-se de colocar título nas imagens). O que se pode concluir?\n","\n","**Dicas:**\n","\n","* O valor de *threshold* sugerido é 220. Observe que para cada kernel, deve-se encontrar um valor mais adequado.\n","\n","*  Faça um ```for loop``` para aplicar os filtros de Sobel. Isso simplifica o código."],"metadata":{"id":"Sb5CsLPrraOA"}},{"cell_type":"code","metadata":{"id":"kyfCSc2_lFmz"},"source":["## -- Seu código começa AQUI -- ##\n","\n","## -- Seu código termina AQUI -- ##"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# DICA: você pode usar um espaço como este para simular os melhores thresholds para cada kernel.\n","\n","#@title Teste Threshold{ run: \"auto\" }\n","\n","Threshold = 177 #@param {type:\"slider\", min:0, max:255, step:1}\n","\n","## -- Seu código começa AQUI -- ##\n","\n","## -- Seu código termina AQUI -- ##"],"metadata":{"id":"yRAgzgNww4YC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2) Influência da iluminação na segmentação (Nota 2.0/10)\n","\n","<center><img src=\"https://github.com/LAVI-USP/SEL0339-SEL5886_2024/raw/main/imagens/pratica_03/abobora_.png\" width=\"256\" height=\"256\"></center>\n","\n","<center><caption><b> Figura 1:</b> Imagem abobora.tif.</b></caption></center>\n","\n","1. Utilize o método de Otsu para binarizar a imagem `abobora.tif`.\n","2. Divida a imagem em 8, 32, 64 e 256 sub-imagens, aplique o método de Otsu em cada uma delas e remonte a imagem final (tenha em mente que a divisão deve ser feita de forma a segmentar em sub-regiões com o máximo de características semelhantes, de forma a se aproveitar da melhor forma o método utilizado).\n","3. Apresente a imagem original e os resultados dos itens 1 e 2 em um subplot. Coloque título em cada plot.\n","4. Comente os resultados obtidos."],"metadata":{"id":"r1ZquowauGVZ"}},{"cell_type":"code","source":["## -- Seu código começa AQUI -- ##\n","\n","## -- Seu código termina AQUI -- ##"],"metadata":{"id":"9qwyWUchulBp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3) Limiarização local (Nota 1.5/10)\n","\n","<center><img src=\"https://github.com/LAVI-USP/SEL0339-SEL5886_2024/raw/main/imagens/pratica_03/sudoku_.png\" width=\"256\" height=\"156\"></center>\n","\n","<center><caption><b> Figura 2:</b> Imagem sudoku.tif.</b></caption></center>\n","\n","1. A imagem `sudoku.tif` possui uma iluminação não uniforme. Aplique a binarização pelo método de limiarização local nessa imagem variando os parâmetros `blockSize` (tamanho da janela) e `C` (constante a ser diminuída da média) de forma a se obter um resultado satisfatório.\n","\n","2. Aplique a binarização pelo método de Otsu e compare com o resultado obtido no item 1.\n","\n","**Dicas:**\n","\n","* A limiarização local pode ser feita pela função [cv.adaptiveThreshold](https://docs.opencv.org/master/d7/d1b/group__imgproc__misc.html#ga72b913f352e4a1b1b397736707afcde3). Utilize o método adaptativo `cv.ADAPTIVE_THRESH_MEAN_C` que calcula o limiar como sendo a média de uma vizinhança `blockSize x blockSize` subtraída de uma constante `C`.\n","\n","``` python\n","# Limiarização local pela média\n","th3 = cv.adaptiveThreshold(img,maxVal,cv.ADAPTIVE_THRESH_MEAN_C,cv.THRESH_BINARY,blockSize,C)\n","```"],"metadata":{"id":"m3S4UaK6ulkg"}},{"cell_type":"code","source":["## -- Seu código começa AQUI -- ##\n","\n","## -- Seu código termina AQUI -- ##"],"metadata":{"id":"l4VlHslruzlH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4) K-means (Nota 3.5/10)\n","\n","Neste exercício, queremos isolar os cartões coloridos da imagem `cores.jpeg`.\n","\n","1. Leia e plote a imagem `cores.jpeg`.\n","2. Converta a imagem lida no item 1 para o espaço de cores HSV.\n","3. Aplique o algoritmo de K-means no canal MATIZ. Escolha o valor k mais adequado. Repare que não será possível isolar todos os cartões neste passo. Mostre os valores máximo e mínimo da imagem resultante. Comente sobre o agrupamento resultante.\n","4. Aplique o algoritmo de K-means no canal SATURAÇÃO. Escolha o valor k mais adequado. Repare que não será possível isolar todos os cartões neste passo. Mostre os valores máximo e mínimo da imagem resultante. Comente sobre o agrupamento resultante.\n","5. Transforme as imagens resultantes dos itens 3 e 4 em máscaras para isolar os cartões destacados. Ou seja, analise um valor de threshold que transforma as imagens em imagens binárias. Mostre as máscaras obtidas.\n","6. Faça uma operação de OR entre as duas máscaras obtidas para obter uma máscara final. Mostre esta máscara.\n","7. Transforme a imagem `cores.jpeg` para o espaço de cores RGB. Aplique, nesta image, a máscara obtida no item 6. Queremos que o fundo fique preto e apenas os cartões coloridos sejam mostrados na imagem.\n","\n","**Dicas:**\n","\n","* Você pode utilizar a função [cv.kmeans](https://docs.opencv.org/master/d5/d38/group__core__cluster.html#ga9a34dc06c6ec9460e90860f15bcd2f88) para a segmentação. Você pode utilizar 20 iterações e epsilon = 0.01 para o K-means.\n","\n","* Para utilizar o K-means você deve passar a imagem como um vetor (1D). O método `.ravel()` e `.flatten()` fazem isso. Além disso, a imagem deve estar em `float32`.\n","\n","* Para retornar a imagem resultante do k-means para o shape original, você pode utilizar a função `img_res.reshape(shape original)`.\n","\n","``` python\n","criterio = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, nIteracao, epsilon)\n","ret,label,centers = cv.kmeans(myVector, nCluster(k), None, criterio, 5, cv.KMEANS_PP_CENTERS)\n","\n","```"],"metadata":{"id":"ilaR4cvrvl-Z"}},{"cell_type":"code","source":["## -- Seu código começa AQUI -- ##\n","\n","## -- Seu código termina AQUI -- ##"],"metadata":{"id":"cnhIAqOVwMHi"},"execution_count":null,"outputs":[]}]}